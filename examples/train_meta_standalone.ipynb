{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "421aea2b-85b8-4a3e-8673-150ee15eb9a3",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/corl-team/xland-minigrid/blob/main/examples/train_meta_standalone.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08db9383-e3e3-423f-b729-af3b8a310805",
   "metadata": {},
   "source": [
    "# Meta-task PPO "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcda9a2f-1685-4962-97a7-3d79754195d6",
   "metadata": {},
   "source": [
    "> âš ï¸ Ensure you select a GPU from `Runtime > Change runtime type`. âš ï¸\n",
    "\n",
    "> ðŸ”¥ Instances with multiple T4 gpus are available on Kaggle for free! Multi-gpu can speed up training with `pmap`. ðŸ”¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3446372-0dcb-45bc-9539-7da52b43b0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xminigrid@ git+https://github.com/corl-team/xland-minigrid.git (from xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Cloning https://github.com/corl-team/xland-minigrid.git to /tmp/pip-install-du4qz__t/xminigrid_cc6218b5ad284452b29b79ee4d7bc1eb\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/corl-team/xland-minigrid.git /tmp/pip-install-du4qz__t/xminigrid_cc6218b5ad284452b29b79ee4d7bc1eb\n",
      "  Resolved https://github.com/corl-team/xland-minigrid.git to commit e3209ee0dd2275598013ce0d36a665a16a876ba4\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: jax>=0.4.13 in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (0.4.23)\n",
      "Requirement already satisfied: jaxlib>=0.4.13 in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (0.4.23+cuda12.cudnn89)\n",
      "Requirement already satisfied: flax>=0.7.0 in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (0.7.5)\n",
      "Requirement already satisfied: rich>=13.4.2 in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (13.7.0)\n",
      "Collecting matplotlib>=3.7.2 (from xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Downloading matplotlib-3.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting imageio>=2.31.2 (from xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Downloading imageio-2.33.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting imageio-ffmpeg>=0.4.9 (from xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Downloading imageio_ffmpeg-0.4.9-py3-none-manylinux2010_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting wandb>=0.15.10 (from xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Downloading wandb-0.16.2-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting pyrallis>=0.3.1 (from xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Downloading pyrallis-0.3.1-py3-none-any.whl (33 kB)\n",
      "Collecting distrax>=0.1.4 (from xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Downloading distrax-0.1.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: optax>=0.1.5 in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (0.1.8)\n",
      "Collecting orbax>=0.1.9 (from xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Downloading orbax-0.1.9.tar.gz (1.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.9.0 in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from distrax>=0.1.4->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (2.1.0)\n",
      "Requirement already satisfied: chex>=0.1.8 in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from distrax>=0.1.4->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (0.1.85)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from distrax>=0.1.4->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (1.26.3)\n",
      "Collecting tensorflow-probability>=0.15.0 (from distrax>=0.1.4->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Downloading tensorflow_probability-0.23.0-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: msgpack in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from flax>=0.7.0->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (1.0.7)\n",
      "Requirement already satisfied: orbax-checkpoint in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from flax>=0.7.0->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (0.5.0)\n",
      "Requirement already satisfied: tensorstore in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from flax>=0.7.0->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (0.1.52)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from flax>=0.7.0->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (4.9.0)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from flax>=0.7.0->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (6.0.1)\n",
      "Collecting pillow>=8.3.2 (from imageio>=2.31.2->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Downloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from imageio-ffmpeg>=0.4.9->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (69.0.3)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from jax>=0.4.13->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from jax>=0.4.13->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.9 in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from jax>=0.4.13->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (1.11.4)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.7.2->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Downloading contourpy-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.7.2->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.7.2->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Downloading fonttools-4.47.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (157 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m157.6/157.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib>=3.7.2->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from matplotlib>=3.7.2->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (23.2)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=3.7.2->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Using cached pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from matplotlib>=3.7.2->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (2.8.2)\n",
      "Collecting typing-inspect (from pyrallis>=0.3.1->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from rich>=13.4.2->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from rich>=13.4.2->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (2.17.2)\n",
      "Collecting Click!=8.0.0,>=7.1 (from wandb>=0.15.10->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb>=0.15.10->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Downloading GitPython-3.1.41-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting requests<3,>=2.0.0 (from wandb>=0.15.10->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from wandb>=0.15.10->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (5.9.7)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb>=0.15.10->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Downloading sentry_sdk-1.39.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb>=0.15.10->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting setproctitle (from wandb>=0.15.10->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Collecting appdirs>=1.4.3 (from wandb>=0.15.10->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from wandb>=0.15.10->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (4.25.2)\n",
      "Requirement already satisfied: toolz>=0.9.0 in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from chex>=0.1.8->distrax>=0.1.4->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (0.12.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb>=0.15.10->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb>=0.15.10->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.4.2->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (0.1.2)\n",
      "Requirement already satisfied: etils[epath,epy] in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from orbax-checkpoint->flax>=0.7.0->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (1.6.0)\n",
      "Requirement already satisfied: nest_asyncio in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from orbax-checkpoint->flax>=0.7.0->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (1.5.9)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.0.0->wandb>=0.15.10->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.0.0->wandb>=0.15.10->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Using cached idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.0.0->wandb>=0.15.10->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Using cached urllib3-2.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.0.0->wandb>=0.15.10->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Using cached certifi-2023.11.17-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from tensorflow-probability>=0.15.0->distrax>=0.1.4->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (5.1.1)\n",
      "Collecting cloudpickle>=1.3 (from tensorflow-probability>=0.15.0->distrax>=0.1.4->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Downloading cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting gast>=0.3.2 (from tensorflow-probability>=0.15.0->distrax>=0.1.4->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting dm-tree (from tensorflow-probability>=0.15.0->distrax>=0.1.4->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Downloading dm_tree-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m152.8/152.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mypy-extensions>=0.3.0 (from typing-inspect->pyrallis>=0.3.1->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.15.10->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git)\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.0->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (2023.12.2)\n",
      "Requirement already satisfied: importlib_resources in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.0->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (6.1.1)\n",
      "Requirement already satisfied: zipp in /opt/anaconda3/envs/minigrid/lib/python3.10/site-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.0->xminigrid@ git+https://github.com/corl-team/xland-minigrid.git->xminigrid[baselines]@ git+https://github.com/corl-team/xland-minigrid.git) (3.17.0)\n",
      "Downloading distrax-0.1.5-py3-none-any.whl (319 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading imageio-2.33.1-py3-none-any.whl (313 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m313.3/313.3 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading imageio_ffmpeg-0.4.9-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading wandb-0.16.2-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (310 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m310.7/310.7 kB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.47.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Downloading sentry_sdk-1.39.2-py2.py3-none-any.whl (254 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_probability-0.23.0-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "Downloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Using cached idna-3.6-py3-none-any.whl (61 kB)\n",
      "Using cached urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
      "Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: xminigrid, orbax\n",
      "  Building wheel for xminigrid (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for xminigrid: filename=xminigrid-0.5.0-py3-none-any.whl size=51842 sha256=b0b2c89efa67051ee30bf44ccc1d055fe42dd2e65f3791b442ebc9ef9ee87123\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-prllgack/wheels/eb/f2/ca/6a50e90c56da3278ffb675a57b98ef22e67233965e39fe279c\n",
      "  Building wheel for orbax (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for orbax: filename=orbax-0.1.9-py3-none-any.whl size=1499 sha256=8fff9f3c8680c4437886e9442aa52172dedb4713e1551bf3ae008bef219cbd01\n",
      "  Stored in directory: /home/p23131/.cache/pip/wheels/14/7a/98/b955a4db98b54317c311ee32367994ca530721c62a87ec56a7\n",
      "Successfully built xminigrid orbax\n",
      "Installing collected packages: dm-tree, appdirs, urllib3, smmap, setproctitle, pyparsing, pillow, mypy-extensions, kiwisolver, imageio-ffmpeg, idna, gast, fonttools, docker-pycreds, cycler, contourpy, cloudpickle, Click, charset-normalizer, certifi, typing-inspect, tensorflow-probability, sentry-sdk, requests, matplotlib, imageio, gitdb, pyrallis, GitPython, wandb, orbax, distrax, xminigrid\n",
      "  Attempting uninstall: xminigrid\n",
      "    Found existing installation: xminigrid 0.5.0\n",
      "    Uninstalling xminigrid-0.5.0:\n",
      "      Successfully uninstalled xminigrid-0.5.0\n",
      "Successfully installed Click-8.1.7 GitPython-3.1.41 appdirs-1.4.4 certifi-2023.11.17 charset-normalizer-3.3.2 cloudpickle-3.0.0 contourpy-1.2.0 cycler-0.12.1 distrax-0.1.5 dm-tree-0.1.8 docker-pycreds-0.4.0 fonttools-4.47.2 gast-0.5.4 gitdb-4.0.11 idna-3.6 imageio-2.33.1 imageio-ffmpeg-0.4.9 kiwisolver-1.4.5 matplotlib-3.8.2 mypy-extensions-1.0.0 orbax-0.1.9 pillow-10.2.0 pyparsing-3.1.1 pyrallis-0.3.1 requests-2.31.0 sentry-sdk-1.39.2 setproctitle-1.3.3 smmap-5.0.1 tensorflow-probability-0.23.0 typing-inspect-0.9.0 urllib3-2.1.0 wandb-0.16.2 xminigrid-0.5.0\n"
     ]
    }
   ],
   "source": [
    "# jax is already installed on the colab, uncomment only if needed\n",
    "# !pip install --upgrade \"jax[cuda11_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
    "\n",
    "# !pip install 'xminigrid[baselines]'\n",
    "# !pip install \"xminigrid[baselines] @ git+https://github.com/corl-team/xland-minigrid.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2df3e354-ce7f-472c-bbb6-05f1b88e343f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataclasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m asdict, dataclass\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partial\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxminigrid\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxminigrid\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvironment\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Environment, EnvParams\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxminigrid\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GymAutoResetWrapper\n",
      "File \u001b[0;32m/opt/anaconda3/envs/minigrid/lib/python3.10/site-packages/xminigrid/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbenchmarks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_benchmark, registered_benchmarks\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make, register, registered_environments\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# TODO: add __all__\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/minigrid/lib/python3.10/site-packages/xminigrid/benchmarks.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree_util\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mjtu\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m struct\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RuleSet\n\u001b[1;32m     15\u001b[0m HF_REPO_ID \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXLAND_MINIGRID_HF_REPO_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHowuhh/xland_minigrid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "from typing import TypedDict\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.tree_util as jtu\n",
    "import flax\n",
    "import flax.linen as nn\n",
    "import distrax\n",
    "import optax\n",
    "import imageio\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from flax import struct\n",
    "from flax.linen.initializers import glorot_normal, orthogonal, zeros_init\n",
    "from flax.training.train_state import TrainState\n",
    "from flax.jax_utils import replicate, unreplicate\n",
    "from dataclasses import asdict, dataclass\n",
    "from functools import partial\n",
    "\n",
    "import xminigrid\n",
    "from xminigrid.environment import Environment, EnvParams\n",
    "from xminigrid.wrappers import GymAutoResetWrapper\n",
    "from xminigrid.benchmarks import Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8cbcf7-4008-440c-9ebf-0e7d26711253",
   "metadata": {},
   "source": [
    "## Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd8fd6-d359-4099-97e7-ad7dd850b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model adapted from minigrid baselines:\n",
    "# https://github.com/lcswillems/rl-starter-files/blob/master/model.py\n",
    "\n",
    "# custom RNN cell, which is more convenient that default in flax\n",
    "class GRU(nn.Module):\n",
    "    hidden_dim: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, xs, init_state):\n",
    "        seq_len, input_dim = xs.shape\n",
    "        # this init might not be optimal, for example bias for reset gate should be -1 (for now ok)\n",
    "        Wi = self.param(\"Wi\", glorot_normal(in_axis=1, out_axis=0), (self.hidden_dim * 3, input_dim))\n",
    "        Wh = self.param(\"Wh\", orthogonal(column_axis=0), (self.hidden_dim * 3, self.hidden_dim))\n",
    "        bi = self.param(\"bi\", zeros_init(), (self.hidden_dim * 3,))\n",
    "        bn = self.param(\"bn\", zeros_init(), (self.hidden_dim,))\n",
    "\n",
    "        def _step_fn(h, x):\n",
    "            igates = jnp.split(Wi @ x + bi, 3)\n",
    "            hgates = jnp.split(Wh @ h, 3)\n",
    "\n",
    "            reset = nn.sigmoid(igates[0] + hgates[0])\n",
    "            update = nn.sigmoid(igates[1] + hgates[1])\n",
    "            new = nn.tanh(igates[2] + reset * (hgates[2] + bn))\n",
    "            next_h = (1 - update) * new + update * h\n",
    "\n",
    "            return next_h, next_h\n",
    "\n",
    "        last_state, all_states = jax.lax.scan(_step_fn, init=init_state, xs=xs)\n",
    "        return all_states, last_state\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    hidden_dim: int\n",
    "    num_layers: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, xs, init_state):\n",
    "        # xs: [seq_len, input_dim]\n",
    "        # init_state: [num_layers, hidden_dim]\n",
    "        outs, states = [], []\n",
    "        for layer in range(self.num_layers):\n",
    "            xs, state = GRU(hidden_dim=self.hidden_dim)(xs, init_state[layer])\n",
    "            outs.append(xs)\n",
    "            states.append(state)\n",
    "\n",
    "        # sum outputs from all layers, kinda like in ResNet\n",
    "        return jnp.array(outs).sum(0), jnp.array(states)\n",
    "\n",
    "BatchedRNNModel = flax.linen.vmap(\n",
    "    RNNModel, variable_axes={\"params\": None}, split_rngs={\"params\": False}, axis_name=\"batch\"\n",
    ")\n",
    "\n",
    "class MaxPool2d(nn.Module):\n",
    "    kernel_size: tuple[int, int]\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        return nn.max_pool(inputs=x, window_shape=self.kernel_size, strides=self.kernel_size, padding=\"VALID\")\n",
    "\n",
    "class ActorCriticInput(TypedDict):\n",
    "    observation: jax.Array\n",
    "    prev_action: jax.Array\n",
    "    prev_reward: jax.Array\n",
    "\n",
    "class ActorCriticRNN(nn.Module):\n",
    "    num_actions: int\n",
    "    action_emb_dim: int = 16\n",
    "    rnn_hidden_dim: int = 64\n",
    "    rnn_num_layers: int = 1\n",
    "    head_hidden_dim: int = 64\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, inputs: ActorCriticInput, hidden: jax.Array) -> tuple[distrax.Categorical, jax.Array, jax.Array]:\n",
    "        B, S = inputs[\"observation\"].shape[:2]\n",
    "        # encoder from https://github.com/lcswillems/rl-starter-files/blob/master/model.py\n",
    "        img_encoder = nn.Sequential(\n",
    "            [\n",
    "                nn.Conv(16, (2, 2), padding=\"VALID\", kernel_init=orthogonal(math.sqrt(2))),\n",
    "                nn.relu,\n",
    "                MaxPool2d((2, 2)),\n",
    "                nn.Conv(32, (2, 2), padding=\"VALID\", kernel_init=orthogonal(math.sqrt(2))),\n",
    "                nn.relu,\n",
    "                nn.Conv(64, (2, 2), padding=\"VALID\", kernel_init=orthogonal(math.sqrt(2))),\n",
    "                nn.relu,\n",
    "            ]\n",
    "        )\n",
    "        action_encoder = nn.Embed(self.num_actions, self.action_emb_dim)\n",
    "\n",
    "        rnn_core = BatchedRNNModel(self.rnn_hidden_dim, self.rnn_num_layers)\n",
    "        actor = nn.Sequential(\n",
    "            [\n",
    "                nn.Dense(self.head_hidden_dim, kernel_init=orthogonal(2)),\n",
    "                nn.tanh,\n",
    "                nn.Dense(self.num_actions, kernel_init=orthogonal(0.01)),\n",
    "            ]\n",
    "        )\n",
    "        critic = nn.Sequential(\n",
    "            [\n",
    "                nn.Dense(self.head_hidden_dim, kernel_init=orthogonal(2)),\n",
    "                nn.tanh,\n",
    "                nn.Dense(1, kernel_init=orthogonal(1.0)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # [batch_size, seq_len, ...]\n",
    "        obs_emb = img_encoder(inputs[\"observation\"]).reshape(B, S, -1)\n",
    "        act_emb = action_encoder(inputs[\"prev_action\"])\n",
    "        # [batch_size, seq_len, hidden_dim + act_emb_dim + 1]\n",
    "        out = jnp.concatenate([obs_emb, act_emb, inputs[\"prev_reward\"][..., None]], axis=-1)\n",
    "        # core networks\n",
    "        out, new_hidden = rnn_core(out, hidden)\n",
    "        dist = distrax.Categorical(logits=actor(out))\n",
    "        values = critic(out)\n",
    "\n",
    "        return dist, jnp.squeeze(values, axis=-1), new_hidden\n",
    "\n",
    "    def initialize_carry(self, batch_size):\n",
    "        return jnp.zeros((batch_size, self.rnn_num_layers, self.rnn_hidden_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa17fc29-d932-49df-bc3b-4c85bb4d4fce",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e326b09-6289-4744-84fa-75f134f7979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training stuff\n",
    "class Transition(struct.PyTreeNode):\n",
    "    done: jax.Array\n",
    "    action: jax.Array\n",
    "    value: jax.Array\n",
    "    reward: jax.Array\n",
    "    log_prob: jax.Array\n",
    "    obs: jax.Array\n",
    "    # for rnn policy\n",
    "    prev_action: jax.Array\n",
    "    prev_reward: jax.Array\n",
    "\n",
    "\n",
    "def calculate_gae(\n",
    "    transitions: Transition,\n",
    "    last_val: jax.Array,\n",
    "    gamma: float,\n",
    "    gae_lambda: float,\n",
    ") -> tuple[jax.Array, jax.Array]:\n",
    "    # single iteration for the loop\n",
    "    def _get_advantages(gae_and_next_value, transition):\n",
    "        gae, next_value = gae_and_next_value\n",
    "        delta = transition.reward + gamma * next_value * (1 - transition.done) - transition.value\n",
    "        gae = delta + gamma * gae_lambda * (1 - transition.done) * gae\n",
    "        return (gae, transition.value), gae\n",
    "\n",
    "    _, advantages = jax.lax.scan(\n",
    "        _get_advantages,\n",
    "        (jnp.zeros_like(last_val), last_val),\n",
    "        transitions,\n",
    "        reverse=True,\n",
    "    )\n",
    "    # advantages and values (Q)\n",
    "    return advantages, advantages + transitions.value\n",
    "\n",
    "\n",
    "def ppo_update_networks(\n",
    "    train_state: TrainState,\n",
    "    transitions: Transition,\n",
    "    init_hstate: jax.Array,\n",
    "    advantages: jax.Array,\n",
    "    targets: jax.Array,\n",
    "    clip_eps: float,\n",
    "    vf_coef: float,\n",
    "    ent_coef: float,\n",
    "):\n",
    "    # NORMALIZE ADVANTAGES\n",
    "    advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n",
    "\n",
    "    def _loss_fn(params):\n",
    "        # RERUN NETWORK\n",
    "        dist, value, _ = train_state.apply_fn(\n",
    "            params,\n",
    "            {\n",
    "                # [batch_size, seq_len, ...]\n",
    "                \"observation\": transitions.obs,\n",
    "                \"prev_action\": transitions.prev_action,\n",
    "                \"prev_reward\": transitions.prev_reward,\n",
    "            },\n",
    "            init_hstate,\n",
    "        )\n",
    "        log_prob = dist.log_prob(transitions.action)\n",
    "\n",
    "        # CALCULATE VALUE LOSS\n",
    "        value_pred_clipped = transitions.value + (value - transitions.value).clip(-clip_eps, clip_eps)\n",
    "        value_loss = jnp.square(value - targets)\n",
    "        value_loss_clipped = jnp.square(value_pred_clipped - targets)\n",
    "        value_loss = 0.5 * jnp.maximum(value_loss, value_loss_clipped).mean()\n",
    "        # TODO: ablate this!\n",
    "        # value_loss = jnp.square(value - targets).mean()\n",
    "\n",
    "        # CALCULATE ACTOR LOSS\n",
    "        ratio = jnp.exp(log_prob - transitions.log_prob)\n",
    "        actor_loss1 = advantages * ratio\n",
    "        actor_loss2 = advantages * jnp.clip(ratio, 1.0 - clip_eps, 1.0 + clip_eps)\n",
    "        actor_loss = -jnp.minimum(actor_loss1, actor_loss2).mean()\n",
    "        entropy = dist.entropy().mean()\n",
    "\n",
    "        total_loss = actor_loss + vf_coef * value_loss - ent_coef * entropy\n",
    "        return total_loss, (value_loss, actor_loss, entropy)\n",
    "\n",
    "    (loss, (vloss, aloss, entropy)), grads = jax.value_and_grad(_loss_fn, has_aux=True)(train_state.params)\n",
    "    (loss, vloss, aloss, entropy, grads) = jax.lax.pmean((loss, vloss, aloss, entropy, grads), axis_name=\"devices\")\n",
    "    train_state = train_state.apply_gradients(grads=grads)\n",
    "    update_info = {\n",
    "        \"total_loss\": loss,\n",
    "        \"value_loss\": vloss,\n",
    "        \"actor_loss\": aloss,\n",
    "        \"entropy\": entropy,\n",
    "    }\n",
    "    return train_state, update_info\n",
    "\n",
    "\n",
    "# for evaluation (evaluate for N consecutive episodes, sum rewards)\n",
    "# N=1 single task, N>1 for meta-RL\n",
    "class RolloutStats(struct.PyTreeNode):\n",
    "    reward: jax.Array = jnp.asarray(0.0)\n",
    "    length: jax.Array = jnp.asarray(0)\n",
    "    episodes: jax.Array = jnp.asarray(0)\n",
    "\n",
    "\n",
    "def rollout(\n",
    "    rng: jax.Array,\n",
    "    env: Environment,\n",
    "    env_params: EnvParams,\n",
    "    train_state: TrainState,\n",
    "    init_hstate: jax.Array,\n",
    "    num_consecutive_episodes: int = 1,\n",
    ") -> RolloutStats:\n",
    "    def _cond_fn(carry):\n",
    "        rng, stats, timestep, prev_action, prev_reward, hstate = carry\n",
    "        return jnp.less(stats.episodes, num_consecutive_episodes)\n",
    "\n",
    "    def _body_fn(carry):\n",
    "        rng, stats, timestep, prev_action, prev_reward, hstate = carry\n",
    "\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        dist, _, hstate = train_state.apply_fn(\n",
    "            train_state.params,\n",
    "            {\n",
    "                \"observation\": timestep.observation[None, None, ...],\n",
    "                \"prev_action\": prev_action[None, None, ...],\n",
    "                \"prev_reward\": prev_reward[None, None, ...],\n",
    "            },\n",
    "            hstate,\n",
    "        )\n",
    "        action = dist.sample(seed=_rng).squeeze()\n",
    "        timestep = env.step(env_params, timestep, action)\n",
    "\n",
    "        stats = stats.replace(\n",
    "            reward=stats.reward + timestep.reward,\n",
    "            length=stats.length + 1,\n",
    "            episodes=stats.episodes + timestep.last(),\n",
    "        )\n",
    "        carry = (rng, stats, timestep, action, timestep.reward, hstate)\n",
    "        return carry\n",
    "\n",
    "    timestep = env.reset(env_params, rng)\n",
    "    prev_action = jnp.asarray(0)\n",
    "    prev_reward = jnp.asarray(0)\n",
    "    init_carry = (rng, RolloutStats(), timestep, prev_action, prev_reward, init_hstate)\n",
    "\n",
    "    final_carry = jax.lax.while_loop(_cond_fn, _body_fn, init_val=init_carry)\n",
    "    return final_carry[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa618e1-03a3-4686-888e-ca771d3b67d1",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407f5829-b77d-4fb5-b12e-43c152b18d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainConfig:\n",
    "    env_id: str = \"XLand-MiniGrid-R1-8x8\"\n",
    "    benchmark_id: str = \"trivial-1m\"\n",
    "    # agent\n",
    "    action_emb_dim: int = 16\n",
    "    rnn_hidden_dim: int = 64\n",
    "    rnn_num_layers: int = 1\n",
    "    head_hidden_dim: int = 64\n",
    "    # training\n",
    "    num_envs: int = 1024\n",
    "    num_steps_per_env: int = 4096\n",
    "    num_steps_per_update: int = 32\n",
    "    update_epochs: int = 1\n",
    "    num_minibatches: int = 16\n",
    "    total_timesteps: int = 100_000_000\n",
    "    lr: float = 0.001\n",
    "    clip_eps: float = 0.2\n",
    "    gamma: float = 0.99\n",
    "    gae_lambda: float = 0.95\n",
    "    ent_coef: float = 0.01\n",
    "    vf_coef: float = 0.5\n",
    "    max_grad_norm: float = 0.5\n",
    "    eval_num_envs: int = 256\n",
    "    eval_num_episodes: int = 10\n",
    "    eval_seed: int = 42\n",
    "    train_seed: int = 42\n",
    "\n",
    "    def __post_init__(self):\n",
    "        num_devices = jax.local_device_count()\n",
    "        \n",
    "        # splitting computation across all available devices\n",
    "        self.num_envs_per_device = self.num_envs // num_devices\n",
    "        self.total_timesteps_per_device = self.total_timesteps // num_devices\n",
    "        self.eval_num_envs_per_device = self.eval_num_envs // num_devices\n",
    "        assert self.num_envs % num_devices == 0\n",
    "        \n",
    "        self.num_meta_updates = round(self.total_timesteps_per_device / (self.num_envs_per_device * self.num_steps_per_env))\n",
    "        self.num_inner_updates = self.num_steps_per_env // self.num_steps_per_update\n",
    "        assert self.num_steps_per_env % self.num_steps_per_update == 0\n",
    "        print(f\"Num devices: {num_devices}, Num meta updates: {self.num_meta_updates}\")\n",
    "\n",
    "\n",
    "def make_states(config: TrainConfig):\n",
    "    # for learning rage scheduling\n",
    "    def linear_schedule(count):\n",
    "        total_inner_updates = config.num_minibatches * config.update_epochs * config.num_inner_updates\n",
    "        frac = 1.0 - (count // total_inner_updates) / config.num_meta_updates\n",
    "        return config.lr * frac\n",
    "\n",
    "    # setup environment\n",
    "    if \"XLand\" not in config.env_id:\n",
    "        raise ValueError(\"Only meta-task environments are supported.\")\n",
    "\n",
    "    env, env_params = xminigrid.make(config.env_id)\n",
    "    env = GymAutoResetWrapper(env)\n",
    "\n",
    "    # loading benchmark\n",
    "    benchmark = xminigrid.load_benchmark(config.benchmark_id)\n",
    "\n",
    "    # set up training state\n",
    "    rng = jax.random.PRNGKey(config.train_seed)\n",
    "    rng, _rng = jax.random.split(rng)\n",
    "\n",
    "    network = ActorCriticRNN(\n",
    "        num_actions=env.num_actions(env_params),\n",
    "        action_emb_dim=config.action_emb_dim,\n",
    "        rnn_hidden_dim=config.rnn_hidden_dim,\n",
    "        rnn_num_layers=config.rnn_num_layers,\n",
    "        head_hidden_dim=config.head_hidden_dim,\n",
    "    )\n",
    "    # [batch_size, seq_len, ...]\n",
    "    init_obs = {\n",
    "        \"observation\": jnp.zeros((config.num_envs_per_device, 1, *env.observation_shape(env_params))),\n",
    "        \"prev_action\": jnp.zeros((config.num_envs_per_device, 1), dtype=jnp.int32),\n",
    "        \"prev_reward\": jnp.zeros((config.num_envs_per_device, 1)),\n",
    "    }\n",
    "    init_hstate = network.initialize_carry(batch_size=config.num_envs_per_device)\n",
    "\n",
    "    network_params = network.init(_rng, init_obs, init_hstate)\n",
    "    tx = optax.chain(\n",
    "        optax.clip_by_global_norm(config.max_grad_norm),\n",
    "        optax.inject_hyperparams(optax.adam)(learning_rate=linear_schedule, eps=1e-8),  # eps=1e-5\n",
    "    )\n",
    "    train_state = TrainState.create(apply_fn=network.apply, params=network_params, tx=tx)\n",
    "\n",
    "    return rng, env, env_params, benchmark, init_hstate, train_state\n",
    "\n",
    "\n",
    "def make_train(\n",
    "    env: Environment,\n",
    "    env_params: EnvParams,\n",
    "    benchmark: Benchmark,\n",
    "    config: TrainConfig,\n",
    "):\n",
    "    @partial(jax.pmap, axis_name=\"devices\")\n",
    "    def train(\n",
    "        rng: jax.Array,\n",
    "        train_state: TrainState,\n",
    "        init_hstate: jax.Array,\n",
    "    ):\n",
    "        # META TRAIN LOOP\n",
    "        def _meta_step(meta_state, _):\n",
    "            rng, train_state = meta_state\n",
    "\n",
    "            # INIT ENV\n",
    "            rng, _rng1, _rng2 = jax.random.split(rng, num=3)\n",
    "            ruleset_rng = jax.random.split(rng, num=config.num_envs_per_device)\n",
    "            reset_rng = jax.random.split(rng, num=config.num_envs_per_device)\n",
    "\n",
    "            # sample rulesets for this meta update\n",
    "            rulesets = jax.vmap(benchmark.sample_ruleset)(ruleset_rng)\n",
    "            meta_env_params = env_params.replace(ruleset=rulesets)\n",
    "\n",
    "            timestep = jax.vmap(env.reset, in_axes=(0, 0))(meta_env_params, reset_rng)\n",
    "            prev_action = jnp.zeros(config.num_envs_per_device, dtype=jnp.int32)\n",
    "            prev_reward = jnp.zeros(config.num_envs_per_device)\n",
    "\n",
    "            # INNER TRAIN LOOP\n",
    "            def _update_step(runner_state, _):\n",
    "                # COLLECT TRAJECTORIES\n",
    "                def _env_step(runner_state, _):\n",
    "                    rng, train_state, prev_timestep, prev_action, prev_reward, prev_hstate = runner_state\n",
    "\n",
    "                    # SELECT ACTION\n",
    "                    rng, _rng = jax.random.split(rng)\n",
    "                    dist, value, hstate = train_state.apply_fn(\n",
    "                        train_state.params,\n",
    "                        {\n",
    "                            # [batch_size, seq_len=1, ...]\n",
    "                            \"observation\": prev_timestep.observation[:, None],\n",
    "                            \"prev_action\": prev_action[:, None],\n",
    "                            \"prev_reward\": prev_reward[:, None],\n",
    "                        },\n",
    "                        prev_hstate,\n",
    "                    )\n",
    "                    action, log_prob = dist.sample_and_log_prob(seed=_rng)\n",
    "                    # squeeze seq_len where possible\n",
    "                    action, value, log_prob = action.squeeze(1), value.squeeze(1), log_prob.squeeze(1)\n",
    "\n",
    "                    # STEP ENV\n",
    "                    timestep = jax.vmap(env.step, in_axes=0)(meta_env_params, prev_timestep, action)\n",
    "                    transition = Transition(\n",
    "                        # ATTENTION: done is always false, as we optimize for entire meta-rollout\n",
    "                        done=jnp.zeros_like(timestep.last()),\n",
    "                        action=action,\n",
    "                        value=value,\n",
    "                        reward=timestep.reward,\n",
    "                        log_prob=log_prob,\n",
    "                        obs=prev_timestep.observation,\n",
    "                        prev_action=prev_action,\n",
    "                        prev_reward=prev_reward,\n",
    "                    )\n",
    "                    runner_state = (rng, train_state, timestep, action, timestep.reward, hstate)\n",
    "                    return runner_state, transition\n",
    "\n",
    "                initial_hstate = runner_state[-1]\n",
    "                # transitions: [seq_len, batch_size, ...]\n",
    "                runner_state, transitions = jax.lax.scan(_env_step, runner_state, None, config.num_steps_per_update)\n",
    "\n",
    "                # CALCULATE ADVANTAGE\n",
    "                rng, train_state, timestep, prev_action, prev_reward, hstate = runner_state\n",
    "                # calculate value of the last step for bootstrapping\n",
    "                _, last_val, _ = train_state.apply_fn(\n",
    "                    train_state.params,\n",
    "                    {\n",
    "                        \"observation\": timestep.observation[:, None],\n",
    "                        \"prev_action\": prev_action[:, None],\n",
    "                        \"prev_reward\": prev_reward[:, None],\n",
    "                    },\n",
    "                    hstate,\n",
    "                )\n",
    "                advantages, targets = calculate_gae(transitions, last_val.squeeze(1), config.gamma, config.gae_lambda)\n",
    "\n",
    "                # UPDATE NETWORK\n",
    "                def _update_epoch(update_state, _):\n",
    "                    def _update_minbatch(train_state, batch_info):\n",
    "                        init_hstate, transitions, advantages, targets = batch_info\n",
    "                        new_train_state, update_info = ppo_update_networks(\n",
    "                            train_state=train_state,\n",
    "                            transitions=transitions,\n",
    "                            init_hstate=init_hstate.squeeze(1),\n",
    "                            advantages=advantages,\n",
    "                            targets=targets,\n",
    "                            clip_eps=config.clip_eps,\n",
    "                            vf_coef=config.vf_coef,\n",
    "                            ent_coef=config.ent_coef,\n",
    "                        )\n",
    "                        return new_train_state, update_info\n",
    "\n",
    "                    rng, train_state, init_hstate, transitions, advantages, targets = update_state\n",
    "\n",
    "                    # MINIBATCHES PREPARATION\n",
    "                    rng, _rng = jax.random.split(rng)\n",
    "                    permutation = jax.random.permutation(_rng, config.num_envs_per_device)\n",
    "                    # [seq_len, batch_size, ...]\n",
    "                    batch = (init_hstate, transitions, advantages, targets)\n",
    "                    # [batch_size, seq_len, ...], as our model assumes\n",
    "                    batch = jtu.tree_map(lambda x: x.swapaxes(0, 1), batch)\n",
    "\n",
    "                    shuffled_batch = jtu.tree_map(lambda x: jnp.take(x, permutation, axis=0), batch)\n",
    "                    # [num_minibatches, minibatch_size, ...]\n",
    "                    minibatches = jtu.tree_map(\n",
    "                        lambda x: jnp.reshape(x, (config.num_minibatches, -1) + x.shape[1:]), shuffled_batch\n",
    "                    )\n",
    "                    train_state, update_info = jax.lax.scan(_update_minbatch, train_state, minibatches)\n",
    "\n",
    "                    update_state = (rng, train_state, init_hstate, transitions, advantages, targets)\n",
    "                    return update_state, update_info\n",
    "\n",
    "                # hstate shape: [seq_len=None, batch_size, num_layers, hidden_dim]\n",
    "                update_state = (rng, train_state, initial_hstate[None, :], transitions, advantages, targets)\n",
    "                update_state, loss_info = jax.lax.scan(_update_epoch, update_state, None, config.update_epochs)\n",
    "                # WARN: do not forget to get updated params\n",
    "                rng, train_state = update_state[:2]\n",
    "\n",
    "                # averaging over minibatches then over epochs\n",
    "                loss_info = jtu.tree_map(lambda x: x.mean(-1).mean(-1), loss_info)\n",
    "                runner_state = (rng, train_state, timestep, prev_action, prev_reward, hstate)\n",
    "                return runner_state, loss_info\n",
    "\n",
    "            # on each meta-update we reset hidden to init_hstate\n",
    "            runner_state = (rng, train_state, timestep, prev_action, prev_reward, init_hstate)\n",
    "            runner_state, loss_info = jax.lax.scan(_update_step, runner_state, None, config.num_inner_updates)\n",
    "            # WARN: do not forget to get updated params\n",
    "            rng, train_state = runner_state[:2]\n",
    "\n",
    "            # EVALUATE AGENT\n",
    "            eval_ruleset_rng, eval_reset_rng = jax.random.split(jax.random.PRNGKey(config.eval_seed))\n",
    "            eval_ruleset_rng = jax.random.split(eval_ruleset_rng, num=config.eval_num_envs_per_device)\n",
    "            eval_reset_rng = jax.random.split(eval_reset_rng, num=config.eval_num_envs_per_device)\n",
    "\n",
    "            eval_ruleset = jax.vmap(benchmark.sample_ruleset)(eval_ruleset_rng)\n",
    "            eval_env_params = env_params.replace(ruleset=eval_ruleset)\n",
    "\n",
    "            eval_stats = jax.vmap(rollout, in_axes=(0, None, 0, None, None, None))(\n",
    "                eval_reset_rng,\n",
    "                env,\n",
    "                eval_env_params,\n",
    "                train_state,\n",
    "                # TODO: make this a static method?\n",
    "                jnp.zeros((1, config.rnn_num_layers, config.rnn_hidden_dim)),\n",
    "                config.eval_num_episodes,\n",
    "            )\n",
    "            eval_stats = jax.lax.pmean(eval_stats, axis_name=\"devices\")\n",
    "\n",
    "            # averaging over inner updates, adding evaluation metrics\n",
    "            loss_info = jtu.tree_map(lambda x: x.mean(-1), loss_info)\n",
    "            loss_info.update(\n",
    "                {\n",
    "                    \"eval/returns_mean\": eval_stats.reward.mean(0),\n",
    "                    \"eval/returns_median\": jnp.median(eval_stats.reward),\n",
    "                    \"eval/lengths\": eval_stats.length.mean(0),\n",
    "                    \"eval/lengths_20percentile\": jnp.percentile(eval_stats.length, q=20),\n",
    "                    \"eval/returns_20percentile\": jnp.percentile(eval_stats.reward, q=20),\n",
    "                    \"lr\": train_state.opt_state[-1].hyperparams[\"learning_rate\"],\n",
    "                }\n",
    "            )\n",
    "            meta_state = (rng, train_state)\n",
    "            return meta_state, loss_info\n",
    "\n",
    "        meta_state = (rng, train_state)\n",
    "        meta_state, loss_info = jax.lax.scan(_meta_step, meta_state, None, config.num_meta_updates)\n",
    "        return {\"state\": meta_state[-1], \"loss_info\": loss_info}\n",
    "\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3b5d4c-bcba-4c44-b0f5-0451189dd721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should take ~8min on colab gpu. It will suboptimal due to the model size and default hyperparams!\n",
    "config = TrainConfig(env_id=\"XLand-MiniGrid-R4-9x9\", benchmark_id=\"trivial-1m\", total_timesteps=100_000_000)\n",
    "\n",
    "rng, env, env_params, benchmark, init_hstate, train_state = make_states(config)\n",
    "# replicating args across devices\n",
    "rng = jax.random.split(rng, num=jax.local_device_count())\n",
    "train_state = replicate(train_state, jax.local_devices())\n",
    "init_hstate = replicate(init_hstate, jax.local_devices())\n",
    "\n",
    "print(\"Compiling...\")\n",
    "t = time.time()\n",
    "train_fn = make_train(env, env_params, benchmark, config)\n",
    "train_fn = train_fn.lower(rng, train_state, init_hstate).compile()\n",
    "elapsed_time = time.time() - t\n",
    "print(f\"Done in {elapsed_time:.2f}s.\")\n",
    "\n",
    "print(\"Training...\")\n",
    "t = time.time()\n",
    "train_info = jax.block_until_ready(train_fn(rng, train_state, init_hstate))\n",
    "elapsed_time = time.time() - t\n",
    "print(f\"Done in {elapsed_time / 60:.2f}min\")\n",
    "\n",
    "# unreplicating from multiple devices\n",
    "train_info = unreplicate(train_info)\n",
    "\n",
    "print(\"Final return: \", float(train_info[\"loss_info\"][\"eval/returns_mean\"][-1]))\n",
    "plt.plot(jnp.arange(config.num_meta_updates), train_info[\"loss_info\"][\"eval/returns_mean\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72527b9-e6f1-4f7e-860b-6e0958c495c7",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1798edfa-bdeb-4f41-8829-7023215f178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xminigrid.rendering.text_render import print_ruleset\n",
    "\n",
    "META_EPISODES = 10\n",
    "\n",
    "env, env_params = xminigrid.make(config.env_id)\n",
    "env = GymAutoResetWrapper(env)\n",
    "\n",
    "ruleset = xminigrid.load_benchmark(config.benchmark_id).get_ruleset(ruleset_id=0)\n",
    "env_params = env_params.replace(ruleset=ruleset)\n",
    "\n",
    "# you can use train_state from the final state also\n",
    "# we just demo here how to do it if you loaded params from the checkpoint\n",
    "params = train_info[\"state\"].params\n",
    "model = ActorCriticRNN(\n",
    "    num_actions=env.num_actions(env_params),\n",
    "    action_emb_dim=config.action_emb_dim,\n",
    "    rnn_hidden_dim=config.rnn_hidden_dim,\n",
    "    rnn_num_layers=config.rnn_num_layers,\n",
    "    head_hidden_dim=config.head_hidden_dim,\n",
    ")\n",
    "\n",
    "# jitting all functions\n",
    "apply_fn, reset_fn, step_fn = jax.jit(model.apply), jax.jit(env.reset), jax.jit(env.step)\n",
    "\n",
    "# for logging\n",
    "total_reward, num_episodes = 0, 0\n",
    "rendered_imgs = []\n",
    "\n",
    "rng = jax.random.PRNGKey(1)\n",
    "rng, _rng = jax.random.split(rng)\n",
    "\n",
    "# initial inputs\n",
    "hidden = model.initialize_carry(1)\n",
    "prev_reward = jnp.asarray(0)\n",
    "prev_action = jnp.asarray(0)\n",
    "\n",
    "timestep = reset_fn(env_params, _rng)\n",
    "rendered_imgs.append(env.render(env_params, timestep))\n",
    "\n",
    "while num_episodes < META_EPISODES:\n",
    "    rng, _rng = jax.random.split(rng)\n",
    "    dist, _, hidden = apply_fn(\n",
    "        params,\n",
    "        {\n",
    "            \"observation\": timestep.observation[None, None, ...],\n",
    "            \"prev_action\": prev_action[None, None, ...],\n",
    "            \"prev_reward\": prev_reward[None, None, ...],\n",
    "        },\n",
    "        hidden,\n",
    "    )\n",
    "    action = dist.sample(seed=_rng).squeeze()\n",
    "\n",
    "    timestep = step_fn(env_params, timestep, action)\n",
    "    prev_action = action\n",
    "    prev_reward = timestep.reward\n",
    "\n",
    "    total_reward += timestep.reward.item()\n",
    "    num_episodes += int(timestep.last().item())\n",
    "    rendered_imgs.append(env.render(env_params, timestep))\n",
    "\n",
    "print(\"Reward:\", total_reward)\n",
    "print(\"Ruleset:\")\n",
    "print_ruleset(ruleset)\n",
    "imageio.mimsave(\"eval_rollout.mp4\", rendered_imgs, fps=16, format=\"mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eea682-badc-499c-afcb-4d87607bd409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"eval_rollout.mp4\", embed=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
